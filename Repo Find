import requests
import re
import json
import os

# Azure DevOps Configuration
organization = "your-org"  # Replace with your Azure DevOps organization
project = "your-project"  # Replace with your Azure DevOps project
personal_access_token = "YOUR_PERSONAL_ACCESS_TOKEN"
base_url = f"https://dev.azure.com/{organization}/{project}/_apis/git/repositories"
auth = ("", personal_access_token)

def read_repositories_from_file(file_path):
    """Read repository names or URLs from a text file."""
    with open(file_path, 'r', encoding='utf-8') as f:
        return [line.strip() for line in f if line.strip()]

def get_repository_id(repo_name):
    """Fetch the repository ID for a given repository name."""
    response = requests.get(f"{base_url}?api-version=7.0", auth=auth)
    if response.status_code == 200:
        repos = response.json()["value"]
        for repo in repos:
            if repo["name"] == repo_name:
                return repo["id"]
    raise Exception(f"Repository '{repo_name}' not found.")

def list_files_in_repository(repo_id):
    """Fetch a list of all files in the repository."""
    url = f"{base_url}/{repo_id}/items?recursionLevel=Full&api-version=7.0"
    response = requests.get(url, auth=auth)
    if response.status_code == 200:
        return response.json()["value"]  # List of files
    else:
        raise Exception(f"Failed to fetch files for repo {repo_id}: {response.status_code}, {response.text}")

def fetch_file_content(repo_id, file_path):
    """Fetch the content of a specific file."""
    url = f"{base_url}/{repo_id}/items?path={file_path}&includeContent=true&api-version=7.0"
    response = requests.get(url, auth=auth)
    if response.status_code == 200:
        return response.json().get("content", "")  # File content
    else:
        raise Exception(f"Failed to fetch file content for {file_path}: {response.status_code}, {response.text}")

def find_patterns_in_repository(repo_id, patterns_mapping):
    """Search for patterns in all files of a repository and generate reports for each pattern set."""
    report = {name: [] for name in patterns_mapping}  # Initialize a report for each pattern set
    regex_mapping = {name: re.compile("|".join(patterns)) for name, patterns in patterns_mapping.items()}  # Compile regex for each pattern set
    files = list_files_in_repository(repo_id)

    for file in files:
        if file.get("isFolder"):  # Skip folders
            continue

        file_path = file.get("path")
        try:
            content = fetch_file_content(repo_id, file_path)
            for name, regex in regex_mapping.items():
                matches = [line.strip() for line in content.splitlines() if regex.search(line)]
                if matches:
                    report[name].append({
                        "file_path": file_path,
                        "matches": matches
                    })
        except Exception as e:
            print(f"Error reading {file_path} in repo {repo_id}: {e}")
    
    return report

def save_report_to_json(report, output_file):
    """Save the report to a JSON file."""
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=4)

def generate_reports_from_repo_list(repo_list_file, patterns_mapping, output_base_dir):
    """Generate reports for repositories listed in a text file."""
    repositories = read_repositories_from_file(repo_list_file)
    os.makedirs(output_base_dir, exist_ok=True)

    for repo_name in repositories:
        print(f"Processing repository: {repo_name}")
        try:
            repo_id = get_repository_id(repo_name)

            # Process the repository for all pattern sets in a single pass
            report = find_patterns_in_repository(repo_id, patterns_mapping)
            for name, matches in report.items():
                if matches:
                    # Save the report if matches are found
                    output_folder = os.path.join(output_base_dir, repo_name)
                    os.makedirs(output_folder, exist_ok=True)
                    output_file = os.path.join(output_folder, f"{name}_report.json")
                    save_report_to_json(matches, output_file)
                    print(f"Report saved: {output_file}")
                else:
                    print(f"No matches found for pattern set '{name}' in repository: {repo_name}")

        except Exception as e:
            print(f"Error processing repository '{repo_name}': {e}")

# ```python
if __name__ == "__main__":
    # Example usage
    repo_list_file = "repositories.txt"  # Path to the file containing repository names
    patterns_mapping = {
        "PatternSet1": ["pattern1", "pattern2"],
        "PatternSet2": ["pattern3", "pattern4"]
    }
    output_base_dir = "reports"  # Directory to save the reports

    generate_reports_from_repo_list(repo_list_file, patterns_mapping, output_base_dir)
